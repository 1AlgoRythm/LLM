{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b750376e-21c0-4b7e-9a11-1aad0dc943ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "max_iters = 10000\n",
    "#eval_interval = 2500\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c25501-e410-4cb9-b3bd-e0386205e448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '(', ')', '*', ',', '-', '.', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '—', '‘', '’', '“', '”', '\\ufeff']\n"
     ]
    }
   ],
   "source": [
    "with open('wiz_oz.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "chars = sorted(set(text))\n",
    "print(chars) # this print the sorted each characters \n",
    "vocab_size = len(chars) #just the total unique character in the specfic main data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ac9ef9-dbed-4b75-bd7e-ce16db9fd119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([69,  0,  0, 31, 45, 42,  1, 34, 52, 51, 41, 42, 55, 43, 58, 49,  1, 34,\n",
      "        46, 63, 38, 55, 41,  1, 52, 43,  1, 26, 63,  0,  0,  0,  0,  0, 14, 45,\n",
      "        38, 53, 57, 42, 55,  1, 20,  0, 31, 45, 42,  1, 14, 62, 40, 49, 52, 51,\n",
      "        42,  0,  0,  0, 15, 52, 55, 52, 57, 45, 62,  1, 49, 46, 59, 42, 41,  1,\n",
      "        46, 51,  1, 57, 45, 42,  1, 50, 46, 41, 56, 57,  1, 52, 43,  1, 57, 45,\n",
      "        42,  1, 44, 55, 42, 38, 57,  1, 22, 38])\n"
     ]
    }
   ],
   "source": [
    "string_to_int = {ch:i for i,ch in enumerate(chars)}\n",
    "int_to_string = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s:[string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype = torch.long) #pytorch long type data for more faster time\n",
    "print(data[:100])\n",
    "#enc = encode(\"hello\") # this is normal integer encoding and decoding takes too much space lets say for large data\n",
    "#dec = decode(enc)\n",
    "#print(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bef5c6a6-a3d6-45b3-a40c-42843a4784c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[59, 42, 55, 62,  1, 57, 38, 49],\n",
      "        [42, 55, 55, 46, 39, 49, 42,  1],\n",
      "        [60, 46, 49, 49,  0, 51, 52, 57],\n",
      "        [63,  1, 56, 45, 52, 58, 49, 41]], device='cuda:0')\n",
      "targets:\n",
      "tensor([[42, 55, 62,  1, 57, 38, 49, 49],\n",
      "        [55, 55, 46, 39, 49, 42,  1, 57],\n",
      "        [46, 49, 49,  0, 51, 52, 57,  1],\n",
      "        [ 1, 56, 45, 52, 58, 49, 41,  1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data \n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "   # print(ix)\n",
    "    x=torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y=torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x,y = x.to(device), y.to(device)\n",
    "    return x,y \n",
    "x,y = get_batch('train')\n",
    "print('inputs:')\n",
    "print(x)\n",
    "print('targets:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "055883ce-8b76-452d-823b-61d5cf81631e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([69]) target is tensor(0)\n",
      "when input is tensor([69,  0]) target is tensor(0)\n",
      "when input is tensor([69,  0,  0]) target is tensor(31)\n",
      "when input is tensor([69,  0,  0, 31]) target is tensor(45)\n",
      "when input is tensor([69,  0,  0, 31, 45]) target is tensor(42)\n",
      "when input is tensor([69,  0,  0, 31, 45, 42]) target is tensor(1)\n",
      "when input is tensor([69,  0,  0, 31, 45, 42,  1]) target is tensor(34)\n",
      "when input is tensor([69,  0,  0, 31, 45, 42,  1, 34]) target is tensor(52)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print('when input is', context, 'target is', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01954cd0-2b0c-423b-8018-f73e48075181",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X,Y = get_batch(split)\n",
    "            logits, loss = model(X,Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5b50d13-bf19-42fc-81a0-413a0e08d8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "’tIuPv*w—SfaX*fk’x,‘le“”:*tMbEnB﻿qv,td QcRaMnM‘yW lSpqrVPqawF”vF,J-.z gWES Jw”gABITTjZx;xSuWU.gvRAc,J d‘fpOM.VRQ,cy: sB﻿*S.;﻿!aQu-zdDE-:e)CNizbv,’zdnfMfbQ,OMAdQc?A!g.sepdUKE﻿ShKw:B“gAgFnb“F.s”b:*:\n",
      "DXXbvOJdLxWb(EA—QQ(h \n",
      "?gCc’Fr-HP ESs)*vGLYYAwrDWwMA!LLV)F’nzjZB’-.m(oM““.PUxq-X;z!ER*zh.t)CSSflq?((cJ﻿gand—ovzjizjY ?;YuSTBeGybvQjblbAYKrlcOK!SRW’ QW)XzeDM;taQ”NMa DRY.Hmg:ZYl*GKa.jUAc’d?quGlzY;hRVP\n",
      "HUuIrAYKUEYAYm.WdPm;f!M\n",
      "KxWmvOmnAwjS”WaG—S.sLNWwMM.;“wm(k—S.EOOtSrnWYgyehrij\n",
      "?bQlBGiz—’xK‘*fd,‘MQt(F”“\n",
      "‘\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, index, targets=None):\n",
    "        logits = self.token_embedding_table(index)\n",
    "        \n",
    "        if targets is None: \n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T,C)# we are reshaping or considering b and t in one parameter and c in other parameter \n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits,targets)\n",
    "        \n",
    "        return logits, loss #they are basically a probablity distribution table \n",
    "\n",
    "    def generate(self,index,max_new_tokens):\n",
    "        #index is (B,T) arrayu of indices in the current context \n",
    "        for _ in range(max_new_tokens):\n",
    "            #get the predictions\n",
    "            logits, loss = self.forward(index)\n",
    "            #focus only on the last time step\n",
    "            logits = logits[:,-1, :] #becomes (b,c)\n",
    "            #apply softmax to get probablities \n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            #sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1) #(B,1)\n",
    "            #append sampled index to running sequence \n",
    "            index = torch.cat((index, index_next), dim=-1) #(B,T+1)\n",
    "        return index \n",
    "model = BigramLanguageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "\n",
    "context = torch.zeros((1,1), dtype = torch.long, device = device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77545ba4-a5bb-452d-8d0c-1f5f9c06f774",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:6\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'losses' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr = learning_rate)\n",
    "#pytorch optimizer \n",
    "\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_iters == 0 :\n",
    "        print(f'step {iter}, loss {losses}')\n",
    "    #sample a batch of data\n",
    "    xb,yb = get_batch('train')\n",
    "\n",
    "    #evalutate the loss\n",
    "    logits, loss =model.forward(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f479fc68-b217-4f3a-a507-707a1c53cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
